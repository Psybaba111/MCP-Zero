pip install vllm
vllm serve "/PATH/TO/Qwen2.5-72B-Instruct" --tensor-parallel-size 8